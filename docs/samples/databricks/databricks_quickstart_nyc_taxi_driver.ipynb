{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "384e5e16-7213-4186-9d04-09d03b155534",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "# Feathr Feature Store on Databricks Demo Notebook\n",
        "\n",
        "This notebook illustrates the use of Feature Store to create a model that predicts NYC Taxi fares. This is a notebook that's specially designed for databricks clusters and is relying on some of the databricks packages such as dbutils.\n",
        "\n",
        "The intent of this notebook is like \"one click run\" without configuring anything, so it has relatively limited capability. \n",
        "\n",
        "- For example, in this notebook there's no feature registry available since that requires running Azure Purview. \n",
        "- Also for online store (Redis), you need to configure the Redis endpoint, otherwise that part will not work. \n",
        "\n",
        "However, the core part of Feathr, especially defining features, get offline features, point-in-time joins etc., should \"just work\". The full-fledged notebook is [located here](https://github.com/linkedin/feathr/blob/main/feathr_project/feathrcli/data/feathr_user_workspace/nyc_driver_demo.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Notebook Steps\n",
        "\n",
        "This tutorial demonstrates the key capabilities of Feathr, including:\n",
        "\n",
        "1. Install and set up Feathr with Azure\n",
        "2. Create shareable features with Feathr feature definition configs.\n",
        "3. Create a training dataset via point-in-time feature join.\n",
        "4. Compute and write features.\n",
        "5. Train a model using these features to predict fares.\n",
        "6. Materialize feature value to online store.\n",
        "7. Fetch feature value in real-time from online store for online scoring.\n",
        "\n",
        "In this tutorial, we use Feathr Feature Store to create a model that predicts NYC Taxi fares. The dataset comes from [here](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). The feature flow is as below:\n",
        "\n",
        "![Feature Flow](https://github.com/linkedin/feathr/blob/main/docs/images/feature_flow.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "f00b9d0b-94d1-418f-89b9-25bbacb8b068",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "! pip install feathr pandavro scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "80223a02-631c-40c8-91b3-a037249ffff9",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import glob\n",
        "import os\n",
        "import tempfile\n",
        "from datetime import datetime, timedelta\n",
        "from math import sqrt\n",
        "\n",
        "import pandas as pd\n",
        "import pandavro as pdx\n",
        "from feathr import FeathrClient\n",
        "from feathr import BOOLEAN, FLOAT, INT32, ValueType\n",
        "from feathr import Feature, DerivedFeature, FeatureAnchor\n",
        "from feathr import BackfillTime, MaterializationSettings\n",
        "from feathr import FeatureQuery, ObservationSettings\n",
        "from feathr import RedisSink\n",
        "from feathr import INPUT_CONTEXT, HdfsSource\n",
        "from feathr import WindowAggTransformation\n",
        "from feathr import TypedKey\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.keyvault.secrets import SecretClient\n",
        "import json\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "41d3648a-9bc9-40dc-90da-bc82b21ef9b3",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "Get the required databricks credentials automatically:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "331753d6-1850-47b5-ad97-84b7c01d79d1",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get current databricks notebook context\n",
        "ctx = dbutils.notebook.entry_point.getDbutils().notebook().getContext()\n",
        "host_name = ctx.tags().get(\"browserHostName\").get()\n",
        "host_token = ctx.apiToken().get()\n",
        "cluster_id = ctx.tags().get(\"clusterId\").get()\n",
        "\n",
        "\n",
        "feathr_runtime_location = \"https://azurefeathrstorage.blob.core.windows.net/public/feathr-assembly-LATEST.jar\"\n",
        "\n",
        "# databricks_config = {'run_name':'FEATHR_FILL_IN','existing_cluster_id':cluster_id,'libraries':[{'jar':'FEATHR_FILL_IN'}],'spark_jar_task':{'main_class_name':'FEATHR_FILL_IN','parameters':['FEATHR_FILL_IN']}}\n",
        "os.environ['spark_config__databricks__workspace_instance_url'] = \"https://\" + host_name\n",
        "os.environ['spark_config__databricks__config_template']='{\"run_name\":\"FEATHR_FILL_IN\",\"new_cluster\":{\"spark_version\":\"10.4.x-scala2.12\",\"node_type_id\":\"Standard_D3_v2\",\"num_workers\":2,\"spark_conf\":{\"FEATHR_FILL_IN\":\"FEATHR_FILL_IN\"}},\"libraries\":[{\"jar\":\"FEATHR_FILL_IN\"}],\"spark_jar_task\":{\"main_class_name\":\"FEATHR_FILL_IN\",\"parameters\":[\"FEATHR_FILL_IN\"]}}'\n",
        "# os.environ['spark_config__databricks__config_template']=json.dumps(databricks_config)\n",
        "os.environ['spark_config__databricks__work_dir']='dbfs:/feathr_getting_started'\n",
        "os.environ['spark_config__databricks__feathr_runtime_location']=feathr_runtime_location\n",
        "os.environ['project_config__project_name']='feathr_getting_started'\n",
        "os.environ['DATABRICKS_WORKSPACE_TOKEN_VALUE'] = host_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You need to setup the Redis credentials below in order to push features to online store. You can skip this part if you don't have Redis, but there  will be failures for `client.materialize_features(settings)` API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get redis credentials; This is to parse Redis connection string.\n",
        "redis_port=\"\"\n",
        "redis_host=\"\"\n",
        "redis_password=\"\"\n",
        "redis_ssl=\"\"\n",
        "\n",
        "# Set the resource link\n",
        "os.environ['online_store__redis__host'] = redis_host\n",
        "os.environ['online_store__redis__port'] = redis_port\n",
        "os.environ['online_store__redis__ssl_enabled'] = redis_ssl\n",
        "os.environ['REDIS_PASSWORD']=redis_password"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "08bc3b7e-bbf5-4e3a-9978-fe1aef8c1aee",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "Configure required credentials (skip if you don't use those):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "8cd64e3a-376c-48e6-ba41-5197f3591d48",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tempfile\n",
        "yaml_config = \"\"\"\n",
        "# Please refer to https://github.com/linkedin/feathr/blob/main/feathr_project/feathrcli/data/feathr_user_workspace/feathr_config.yaml for explanations on the meaning of each field.\n",
        "api_version: 1\n",
        "project_config:\n",
        "  project_name: 'feathr_getting_started2'\n",
        "  required_environment_variables:\n",
        "    - 'REDIS_PASSWORD'\n",
        "    - 'AZURE_CLIENT_ID'\n",
        "    - 'AZURE_TENANT_ID'\n",
        "    - 'AZURE_CLIENT_SECRET'\n",
        "offline_store:\n",
        "  adls:\n",
        "    adls_enabled: true\n",
        "  wasb:\n",
        "    wasb_enabled: true\n",
        "  s3:\n",
        "    s3_enabled: false\n",
        "    s3_endpoint: 's3.amazonaws.com'\n",
        "  jdbc:\n",
        "    jdbc_enabled: false\n",
        "    jdbc_database: 'feathrtestdb'\n",
        "    jdbc_table: 'feathrtesttable'\n",
        "  snowflake:\n",
        "    url: \"dqllago-ol19457.snowflakecomputing.com\"\n",
        "    user: \"feathrintegration\"\n",
        "    role: \"ACCOUNTADMIN\"\n",
        "spark_config:\n",
        "  # choice for spark runtime. Currently support: azure_synapse, databricks\n",
        "  # The `databricks` configs will be ignored if `azure_synapse` is set and vice versa.\n",
        "  spark_cluster: \"databricks\"\n",
        "  spark_result_output_parts: \"1\"\n",
        "\n",
        "online_store:\n",
        "  redis:\n",
        "    host: 'feathrazuretest3redis.redis.cache.windows.net'\n",
        "    port: 6380\n",
        "    ssl_enabled: True\n",
        "feature_registry:\n",
        "  purview:\n",
        "    type_system_initialization: true\n",
        "    purview_name: 'feathrazuretest3-purview1'\n",
        "    delimiter: '__'\n",
        "\"\"\"\n",
        "tmp = tempfile.NamedTemporaryFile(mode='w', delete=False)\n",
        "with open(tmp.name, \"w\") as text_file:\n",
        "    text_file.write(yaml_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "3fef7f2f-df19-4f53-90a5-ff7999ed983d",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "# Initialize Feathr Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "9713a2df-c7b2-4562-88b0-b7acce3cc43a",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "client = FeathrClient(config_path=tmp.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "c3b64bda-d42c-4a64-b976-0fb604cf38c5",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "## View the data\n",
        "\n",
        "In this tutorial, we use Feathr Feature Store to create a model that predicts NYC Taxi fares. The dataset comes from [here](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). The data is as below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "c4ccd7b3-298a-4e5a-8eec-b7e309db393e",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.read_csv(\"https://azurefeathrstorage.blob.core.windows.net/public/sample_data/green_tripdata_2020-04_with_index.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "7430c942-64e5-4b70-b823-16ce1d1b3cee",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "## Defining Features with Feathr\n",
        "\n",
        "In Feathr, a feature is viewed as a function, mapping from entity id or key, and timestamp to a feature value. For more details on feature definition, please refer to the [Feathr Feature Definition Guide](https://github.com/linkedin/feathr/blob/main/docs/concepts/feature-definition.md)\n",
        "\n",
        "\n",
        "1. The typed key (a.k.a. entity id) identifies the subject of feature, e.g. a user id, 123.\n",
        "2. The feature name is the aspect of the entity that the feature is indicating, e.g. the age of the user.\n",
        "3. The feature value is the actual value of that aspect at a particular time, e.g. the value is 30 at year 2022."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "16420730-582e-4e11-a343-efc0ddd35108",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "Note that, in some cases, such as features defined on top of request data, may have no entity key or timestamp.\n",
        "It is merely a function/transformation executing against request data at runtime.\n",
        "For example, the day of week of the request, which is calculated by converting the request UNIX timestamp."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "728d2d5f-c11f-4941-bdc5-48507f5749f1",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "### Define Sources Section with UDFs\n",
        "A feature source is needed for anchored features that describes the raw data in which the feature values are computed from. See the python documentation to get the details on each input column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "3cc59a0e-a41b-480e-a84e-ca5443d63143",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "batch_source = HdfsSource(name=\"nycTaxiBatchSource\",\n",
        "                          path=\"wasbs://public@azurefeathrstorage.blob.core.windows.net/sample_data/green_tripdata_2020-04_with_index.csv\",\n",
        "                          event_timestamp_column=\"lpep_dropoff_datetime\",\n",
        "                          timestamp_format=\"yyyy-MM-dd HH:mm:ss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "46f863c4-bb81-434a-a448-6b585031a221",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "### Define Anchors and Features\n",
        "A feature is called an anchored feature when the feature is directly extracted from the source data, rather than computed on top of other features. The latter case is called derived feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "a373ecbe-a040-4cd3-9d87-0d5f4c5ba553",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "f_trip_distance = Feature(name=\"f_trip_distance\",\n",
        "                          feature_type=FLOAT, transform=\"trip_distance\")\n",
        "\n",
        "features = [\n",
        "    f_trip_distance,\n",
        "    Feature(name=\"f_is_long_trip_distance\",\n",
        "            feature_type=BOOLEAN,\n",
        "            transform=\"cast_float(trip_distance)>30\"),\n",
        "    Feature(name=\"f_day_of_week\",\n",
        "            feature_type=INT32,\n",
        "            transform=\"dayofweek(lpep_dropoff_datetime)\"),\n",
        "]\n",
        "\n",
        "request_anchor = FeatureAnchor(name=\"request_features\",\n",
        "                               source=INPUT_CONTEXT,\n",
        "                               features=features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "149f85e2-fa3c-4895-b0c5-de5543ca9b6d",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "### Window aggregation features\n",
        "\n",
        "For window aggregation features, see the supported fields below:\n",
        "\n",
        "Note that the `agg_func` should be any of these:\n",
        "\n",
        "| Aggregation Type | Input Type | Description |\n",
        "| --- | --- | --- |\n",
        "|SUM, COUNT, MAX, MIN, AVG\t|Numeric|Applies the the numerical operation on the numeric inputs. |\n",
        "|MAX_POOLING, MIN_POOLING, AVG_POOLING\t| Numeric Vector | Applies the max/min/avg operation on a per entry bassis for a given a collection of numbers.|\n",
        "|LATEST| Any |Returns the latest not-null values from within the defined time window |\n",
        "\n",
        "\n",
        "After you have defined features and sources, bring them together to build an anchor:\n",
        "\n",
        "\n",
        "Note that if the data source is from the observation data, the `source` section should be `INPUT_CONTEXT` to indicate the source of those defined anchors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "05633bc3-9118-449b-9562-45fc437576c2",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "location_id = TypedKey(key_column=\"DOLocationID\",\n",
        "                       key_column_type=ValueType.INT32,\n",
        "                       description=\"location id in NYC\",\n",
        "                       full_name=\"nyc_taxi.location_id\")\n",
        "agg_features = [Feature(name=\"f_location_avg_fare\",\n",
        "                        key=location_id,\n",
        "                        feature_type=FLOAT,\n",
        "                        transform=WindowAggTransformation(agg_expr=\"cast_float(fare_amount)\",\n",
        "                                                          agg_func=\"AVG\",\n",
        "                                                          window=\"90d\")),\n",
        "                Feature(name=\"f_location_max_fare\",\n",
        "                        key=location_id,\n",
        "                        feature_type=FLOAT,\n",
        "                        transform=WindowAggTransformation(agg_expr=\"cast_float(fare_amount)\",\n",
        "                                                          agg_func=\"MAX\",\n",
        "                                                          window=\"90d\")),\n",
        "                ]\n",
        "\n",
        "agg_anchor = FeatureAnchor(name=\"aggregationFeatures\",\n",
        "                           source=batch_source,\n",
        "                           features=agg_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "d2ecaca9-057e-4b36-811f-320f66f753ed",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "### Derived Features Section\n",
        "Derived features are the features that are computed from other features. They could be computed from anchored features, or other derived features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "270fb11e-8a71-404f-9639-ad29d8e6a2c1",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "f_trip_distance_rounded = DerivedFeature(name=\"f_trip_distance_rounded\",\n",
        "                                     feature_type=INT32,\n",
        "                                     input_features=[f_trip_distance],\n",
        "                                     transform=\"f_trip_distance * 10\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "ad102c45-586d-468c-85f0-9454401ef10b",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "And then we need to build those features so that it can be consumed later. Note that we have to build both the \"anchor\" and the \"derived\" features (which is not anchored to a source)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "91bb5ebb-87e4-470b-b8eb-1c89b351740e",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "client.build_features(anchor_list=[agg_anchor, request_anchor], derived_feature_list=[\n",
        "                       f_trip_distance_rounded])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "632d5f46-f9e2-41a8-aab7-34f75206e2aa",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "## Create training data using point-in-time correct feature join\n",
        "\n",
        "A training dataset usually contains entity id columns, multiple feature columns, event timestamp column and label/target column. \n",
        "\n",
        "To create a training dataset using Feathr, one needs to provide a feature join configuration file to specify\n",
        "what features and how these features should be joined to the observation data. \n",
        "\n",
        "To learn more on this topic, please refer to [Point-in-time Correctness](https://github.com/linkedin/feathr/blob/main/docs/concepts/point-in-time-join.md)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "e438e6d8-162e-4aa3-b3b3-9d1f3b0d2b7f",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "output_path = 'dbfs:/feathrazure_test.avro'\n",
        "\n",
        "\n",
        "feature_query = FeatureQuery(\n",
        "    feature_list=[\"f_location_avg_fare\", \"f_trip_distance_rounded\", \"f_is_long_trip_distance\"], key=location_id)\n",
        "settings = ObservationSettings(\n",
        "    observation_path=\"wasbs://public@azurefeathrstorage.blob.core.windows.net/sample_data/green_tripdata_2020-04_with_index.csv\",\n",
        "    event_timestamp_column=\"lpep_dropoff_datetime\",\n",
        "    timestamp_format=\"yyyy-MM-dd HH:mm:ss\")\n",
        "client.get_offline_features(observation_settings=settings,\n",
        "                            feature_query=feature_query,\n",
        "                            output_path=output_path\n",
        "                           )\n",
        "client.wait_job_to_finish(timeout_sec=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "51f078e3-3f8f-4f10-b7f1-499ac8a9ff07",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "## Download the result and show the result\n",
        "\n",
        "Let's use the helper function `get_result_df` to download the result and view it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "23c797b2-ac1a-4cf3-b0ed-c05216de3f37",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from feathr.utils.job_utils import get_result_df\n",
        "df_res = get_result_df(client, format=\"avro\", res_url = output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "b9be042e-eb12-46b9-9d91-a0e5dd0c704f",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "dcbf17fc-7f79-4a65-a3af-9cffbd0b5d1f",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "## Train a machine learning model\n",
        "After getting all the features, let's train a machine learning model with the converted feature by Feathr:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "84745f36-5bac-49c0-903b-38828b923c7c",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# remove columns\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "final_df = df_res\n",
        "final_df.drop([\"lpep_pickup_datetime\", \"lpep_dropoff_datetime\",\n",
        "              \"store_and_fwd_flag\"], axis=1, inplace=True, errors='ignore')\n",
        "final_df.fillna(0, inplace=True)\n",
        "final_df['fare_amount'] = final_df['fare_amount'].astype(\"float64\")\n",
        "\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(final_df.drop([\"fare_amount\"], axis=1),\n",
        "                                                    final_df[\"fare_amount\"],\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "model = GradientBoostingRegressor()\n",
        "model.fit(train_x, train_y)\n",
        "\n",
        "y_predict = model.predict(test_x)\n",
        "\n",
        "y_actual = test_y.values.flatten().tolist()\n",
        "rmse = sqrt(mean_squared_error(y_actual, y_predict))\n",
        "\n",
        "sum_actuals = sum_errors = 0\n",
        "\n",
        "for actual_val, predict_val in zip(y_actual, y_predict):\n",
        "    abs_error = actual_val - predict_val\n",
        "    if abs_error < 0:\n",
        "        abs_error = abs_error * -1\n",
        "\n",
        "    sum_errors = sum_errors + abs_error\n",
        "    sum_actuals = sum_actuals + actual_val\n",
        "\n",
        "mean_abs_percent_error = sum_errors / sum_actuals\n",
        "print(\"Model MAPE:\")\n",
        "print(mean_abs_percent_error)\n",
        "print()\n",
        "print(\"Model Accuracy:\")\n",
        "print(1 - mean_abs_percent_error)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "5a226026-1c7b-48db-8f91-88d5c2ddf023",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "## Materialize feature value into offline/online storage\n",
        "\n",
        "While Feathr can compute the feature value from the feature definition on-the-fly at request time, it can also pre-compute\n",
        "and materialize the feature value to offline and/or online storage. \n",
        "\n",
        "We can push the generated features to the online store like below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "3b924c66-8634-42fe-90f3-c844487d3f75",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "backfill_time = BackfillTime(start=datetime(\n",
        "    2020, 5, 20), end=datetime(2020, 5, 20), step=timedelta(days=1))\n",
        "redisSink = RedisSink(table_name=\"nycTaxiDemoFeature\")\n",
        "settings = MaterializationSettings(\"nycTaxiTable\",\n",
        "                                   backfill_time=backfill_time,\n",
        "                                   sinks=[redisSink],\n",
        "                                   feature_names=[\"f_location_avg_fare\", \"f_location_max_fare\"])\n",
        "\n",
        "client.materialize_features(settings)\n",
        "client.wait_job_to_finish(timeout_sec=500)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "6a3e2ab1-5c66-4d27-a737-c5e2af03b1dd",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "We can then get the features from the online store (Redis):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "bef93538-9591-4247-97b6-289d2055b7b1",
          "showTitle": false,
          "title": ""
        }
      },
      "source": [
        "## Fetching feature value for online inference\n",
        "\n",
        "For features that are already materialized by the previous step, their latest value can be queried via the client's\n",
        "`get_online_features` or `multi_get_online_features` API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "0c3d5f35-11a3-4644-9992-5860169d8302",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "res = client.get_online_features('nycTaxiDemoFeature', '265', [\n",
        "                                 'f_location_avg_fare', 'f_location_max_fare'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "4d4699ed-42e6-408f-903d-2f799284f4b6",
          "showTitle": false,
          "title": ""
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style scoped>\n",
              "  .ansiout {\n",
              "    display: block;\n",
              "    unicode-bidi: embed;\n",
              "    white-space: pre-wrap;\n",
              "    word-wrap: break-word;\n",
              "    word-break: break-all;\n",
              "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
              "    font-size: 13px;\n",
              "    color: #555;\n",
              "    margin-left: 4px;\n",
              "    line-height: 19px;\n",
              "  }\n",
              "</style>"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "arguments": {},
              "data": "",
              "errorSummary": "",
              "errorTraceType": null,
              "metadata": {},
              "type": "ipynbError"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "client.multi_get_online_features(\"nycTaxiDemoFeature\", [\"239\", \"265\"], [\n",
        "                                 'f_location_avg_fare', 'f_location_max_fare'])"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "nyc_driver_demo",
      "notebookOrigID": 930353059183053,
      "widgets": {}
    },
    "interpreter": {
      "hash": "830c16c5b424e7ff512f67d4056b67cea1a756a7ad6a92c98b9e2b95c5e484ae"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}