{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feathr Feature Store on Azure Demo Notebook\n",
    "\n",
    "This notebook illustrates the use of Feature Store to create a model that predicts NYC Taxi fares. It includes these steps:\n",
    "\n",
    "\n",
    "This tutorial demonstrates the key capabilities of Feathr, including:\n",
    "\n",
    "1. Install and set up Feathr with Azure\n",
    "2. Create shareable features with Feathr feature definition configs.\n",
    "3. Create a training dataset via point-in-time feature join.\n",
    "4. Compute and write features.\n",
    "5. Train a model using these features to predict fares.\n",
    "6. Materialize feature value to online store.\n",
    "7. Fetch feature value in real-time from online store for online scoring.\n",
    "\n",
    "In this tutorial, we use Feathr Feature Store to create a model that predicts NYC Taxi fares. The dataset comes from [here](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). The feature flow is as below:\n",
    "\n",
    "![Feature Flow](https://github.com/linkedin/feathr/blob/main/docs/images/feature_flow.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite: Provision cloud resources\n",
    "\n",
    "First step is to provision required cloud resources if you want to use Feathr. Feathr provides a python based client to interact with cloud resources.\n",
    "\n",
    "Please follow the steps [here]() to provision required cloud resources. Due to the complexity of the possible cloud environment, it is almost impossible to create a script that works for all the use cases. Because of this, [azure_resource_provision.sh](https://github.com/linkedin/feathr/blob/main/docs/how-to-guides/azure_resource_provision.sh) is a full end to end command line to create all the required resources, and you can tailor the script as needed, while [the companion documentation](https://github.com/linkedin/feathr/blob/main/docs/how-to-guides/azure-deployment.md) can be used as a complete guide for using that shell script.\n",
    "\n",
    "At the end of the script, it should give you some output which you will need later. For example, the Service Principal IDs, Redis endpoint, etc.\n",
    "\n",
    "Please also note that at the end of this step, you need to **manually** grant your service principal \"Data Curator\" permission of your Azure Purview account, due to a current limiation with Azure Purview.\n",
    "\n",
    "And the architecture is as below:\n",
    "\n",
    "![Architecture](https://github.com/linkedin/feathr/blob/main/docs/images/architecture.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite: Install Feathr\n",
    "\n",
    "Install Feathr using pip:\n",
    "\n",
    "`pip install -U feathr pandavro scikit-learn`\n",
    "\n",
    "Or if you want to use the latest Feathr code from GitHub:\n",
    "\n",
    "`pip install -I git+https://github.com/linkedin/feathr.git#subdirectory=feathr_project pandavro scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite: Configure the required environment\n",
    "\n",
    "In the first step (Provision cloud resources), you should have provisioned all the required cloud resources. If you use Feathr CLI to create a workspace, you should have a folder with a file called `feathr_config.yaml` in it with all the required configurations. Otherwise, update the configuration below.\n",
    "\n",
    "The code below will write this configuration string to a temporary location and load it to Feathr. Please still refer to [feathr_config.yaml](https://github.com/linkedin/feathr/blob/main/feathr_project/feathrcli/data/feathr_user_workspace/feathr_config.yaml) and use that as the source of truth. It should also have more explanations on the meaning of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "yaml_config = \"\"\"\n",
    "# Please refer to https://github.com/linkedin/feathr/blob/main/feathr_project/feathrcli/data/feathr_user_workspace/feathr_config.yaml for explanations on the meaning of each field.\n",
    "api_version: 1\n",
    "project_config:\n",
    "  project_name: 'feathr_sample'\n",
    "  required_environment_variables:\n",
    "    - 'REDIS_PASSWORD'\n",
    "    - 'AZURE_CLIENT_ID'\n",
    "    - 'AZURE_TENANT_ID'\n",
    "    - 'AZURE_CLIENT_SECRET'\n",
    "offline_store:\n",
    "  adls:\n",
    "    adls_enabled: true\n",
    "  wasb:\n",
    "    wasb_enabled: true\n",
    "  s3:\n",
    "    s3_enabled: false\n",
    "    s3_endpoint: 's3.amazonaws.com'\n",
    "  jdbc:\n",
    "    jdbc_enabled: false\n",
    "    jdbc_database: 'feathrtestdb'\n",
    "    jdbc_table: 'feathrtesttable'\n",
    "  snowflake:\n",
    "    url: \"dqllago-ol19457.snowflakecomputing.com\"\n",
    "    user: \"feathrintegration\"\n",
    "    role: \"ACCOUNTADMIN\"\n",
    "spark_config:\n",
    "  spark_cluster: 'azure_synapse'\n",
    "  spark_result_output_parts: '1'\n",
    "  azure_synapse:\n",
    "    dev_url: 'https://feathrazuretest3synapse.dev.azuresynapse.net'\n",
    "    pool_name: 'spark3'\n",
    "    workspace_dir: 'abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started'\n",
    "    executor_size: 'Small'\n",
    "    executor_num: 4\n",
    "    feathr_runtime_location: wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar\n",
    "  databricks:\n",
    "    workspace_instance_url: 'https://adb-6885802458123232.12.azuredatabricks.net/'\n",
    "    workspace_token_value: ''\n",
    "    config_template: {'run_name':'','new_cluster':{'spark_version':'9.1.x-scala2.12','node_type_id':'Standard_D3_v2','num_workers':2,'spark_conf':{}},'libraries':[{'jar':''}],'spark_jar_task':{'main_class_name':'','parameters':['']}}\n",
    "    work_dir: 'dbfs:/feathr_getting_started'\n",
    "    feathr_runtime_location: wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar\n",
    "online_store:\n",
    "  redis:\n",
    "    host: 'feathrazuretest3redis.redis.cache.windows.net'\n",
    "    port: 6380\n",
    "    ssl_enabled: True\n",
    "feature_registry:\n",
    "  purview:\n",
    "    type_system_initialization: true\n",
    "    purview_name: 'feathrazuretest3-purview1'\n",
    "    delimiter: '__'\n",
    "\"\"\"\n",
    "tmp = tempfile.NamedTemporaryFile(mode='w', delete=False)\n",
    "with open(tmp.name, \"w\") as text_file:\n",
    "    text_file.write(yaml_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the data\n",
    "\n",
    "In this tutorial, we use Feathr Feature Store to create a model that predicts NYC Taxi fares. The dataset comes from [here](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). The data is as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/ipykernel_92744/3211500075.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(\"https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2020-04.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-04-01 00:44:02</td>\n",
       "      <td>2020-04-01 00:52:23</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-04-01 00:24:39</td>\n",
       "      <td>2020-04-01 00:33:06</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>244</td>\n",
       "      <td>247</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.94</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-04-01 00:45:06</td>\n",
       "      <td>2020-04-01 00:51:13</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>244</td>\n",
       "      <td>243</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-04-01 00:45:06</td>\n",
       "      <td>2020-04-01 01:04:39</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>244</td>\n",
       "      <td>243</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.81</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-04-01 00:00:23</td>\n",
       "      <td>2020-04-01 00:16:13</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75</td>\n",
       "      <td>169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.79</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>22.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35607</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-30 23:29:00</td>\n",
       "      <td>2020-04-30 23:57:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.41</td>\n",
       "      <td>35.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>42.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35608</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-30 23:11:00</td>\n",
       "      <td>2020-04-30 23:47:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188</td>\n",
       "      <td>230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.17</td>\n",
       "      <td>35.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>38.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35609</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-30 23:18:00</td>\n",
       "      <td>2020-04-30 23:46:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.37</td>\n",
       "      <td>34.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>34.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35610</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-30 23:55:00</td>\n",
       "      <td>2020-05-01 00:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.25</td>\n",
       "      <td>16.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35611</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-30 23:01:00</td>\n",
       "      <td>2020-04-30 23:02:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>23.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>23.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35612 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0           2.0  2020-04-01 00:44:02   2020-04-01 00:52:23                  N   \n",
       "1           2.0  2020-04-01 00:24:39   2020-04-01 00:33:06                  N   \n",
       "2           2.0  2020-04-01 00:45:06   2020-04-01 00:51:13                  N   \n",
       "3           2.0  2020-04-01 00:45:06   2020-04-01 01:04:39                  N   \n",
       "4           2.0  2020-04-01 00:00:23   2020-04-01 00:16:13                  N   \n",
       "...         ...                  ...                   ...                ...   \n",
       "35607       NaN  2020-04-30 23:29:00   2020-04-30 23:57:00                NaN   \n",
       "35608       NaN  2020-04-30 23:11:00   2020-04-30 23:47:00                NaN   \n",
       "35609       NaN  2020-04-30 23:18:00   2020-04-30 23:46:00                NaN   \n",
       "35610       NaN  2020-04-30 23:55:00   2020-05-01 00:10:00                NaN   \n",
       "35611       NaN  2020-04-30 23:01:00   2020-04-30 23:02:00                NaN   \n",
       "\n",
       "       RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0             1.0            42            41              1.0           1.68   \n",
       "1             1.0           244           247              2.0           1.94   \n",
       "2             1.0           244           243              3.0           1.00   \n",
       "3             1.0           244           243              2.0           2.81   \n",
       "4             1.0            75           169              1.0           6.79   \n",
       "...           ...           ...           ...              ...            ...   \n",
       "35607         NaN            37           147              NaN          11.41   \n",
       "35608         NaN           188           230              NaN          11.17   \n",
       "35609         NaN           205            37              NaN          14.37   \n",
       "35610         NaN            37           188              NaN           4.25   \n",
       "35611         NaN           185           185              NaN           0.01   \n",
       "\n",
       "       fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0             8.00    0.5      0.5         0.0          0.00        NaN   \n",
       "1             9.00    0.5      0.5         0.0          0.00        NaN   \n",
       "2             6.50    0.5      0.5         0.0          0.00        NaN   \n",
       "3            12.00    0.5      0.5         0.0          0.00        NaN   \n",
       "4            21.00    0.5      0.5         0.0          0.00        NaN   \n",
       "...            ...    ...      ...         ...           ...        ...   \n",
       "35607        35.82    0.0      0.0         0.0          6.12        NaN   \n",
       "35608        35.45    0.0      0.0         0.0          0.00        NaN   \n",
       "35609        34.54    0.0      0.0         0.0          0.00        NaN   \n",
       "35610        16.72    0.0      0.0         0.0          0.00        NaN   \n",
       "35611        23.17    0.0      0.0         0.0          0.00        NaN   \n",
       "\n",
       "       improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                        0.3          9.30           1.0        1.0   \n",
       "1                        0.3         10.30           2.0        1.0   \n",
       "2                        0.3          7.80           2.0        1.0   \n",
       "3                        0.3         13.30           2.0        1.0   \n",
       "4                        0.3         22.30           1.0        1.0   \n",
       "...                      ...           ...           ...        ...   \n",
       "35607                    0.3         42.24           NaN        NaN   \n",
       "35608                    0.3         38.50           NaN        NaN   \n",
       "35609                    0.3         34.84           NaN        NaN   \n",
       "35610                    0.3         17.02           NaN        NaN   \n",
       "35611                    0.3         23.47           NaN        NaN   \n",
       "\n",
       "       congestion_surcharge  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "...                     ...  \n",
       "35607                   NaN  \n",
       "35608                   NaN  \n",
       "35609                   NaN  \n",
       "35610                   NaN  \n",
       "35611                   NaN  \n",
       "\n",
       "[35612 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2020-04.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import tempfile\n",
    "from datetime import datetime, timedelta\n",
    "from math import sqrt\n",
    "\n",
    "import pandas as pd\n",
    "import pandavro as pdx\n",
    "from feathr import FeathrClient\n",
    "from feathr.anchor import FeatureAnchor\n",
    "from feathr.client import FeathrClient\n",
    "from feathr.dtype import BOOLEAN, FLOAT, INT32, ValueType\n",
    "from feathr.feature import Feature\n",
    "from feathr.feature_derivations import DerivedFeature\n",
    "from feathr.materialization_settings import (BackfillTime,\n",
    "                                             MaterializationSettings)\n",
    "from feathr.query_feature_list import FeatureQuery\n",
    "from feathr.settings import ObservationSettings\n",
    "from feathr.sink import RedisSink\n",
    "from feathr.source import INPUT_CONTEXT, HdfsSource\n",
    "from feathr.transformation import WindowAggTransformation\n",
    "from feathr.typed_key import TypedKey\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup necessary environment variables\n",
    "\n",
    "You have to setup the environment variables in order to run this sample. More environment variables can be set by referring to [feathr_config.yaml](https://github.com/linkedin/feathr/blob/main/feathr_project/feathrcli/data/feathr_user_workspace/feathr_config.yaml) and use that as the source of truth. It should also have more explanations on the meaning of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['REDIS_PASSWORD'] = ''\n",
    "os.environ['AZURE_CLIENT_ID'] = ''\n",
    "os.environ['AZURE_TENANT_ID'] = ''\n",
    "os.environ['AZURE_CLIENT_SECRET'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will initialize a feathr client:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = FeathrClient(config_path=tmp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features with Feathr:\n",
    "\n",
    "In Feathr, a feature is viewed as a function, mapping from entity id or key, and timestamp to a feature value.\n",
    "\n",
    "1. The entity key (a.k.a. entity id) identifies the subject of feature, e.g. a user id, 123.\n",
    "2. The feature name is the aspect of the entity that the feature is indicating, e.g. the age of the user.\n",
    "3. The feature value is the actual value of that aspect at a particular time, e.g. the value is 30 at year 2022.\n",
    "\n",
    "Note that, in some cases, such as features defined on top of request data, may have no entity key or timestamp.\n",
    "It is merely a function/transformation executing against request data at runtime.\n",
    "For example, the day of week of the request, which is calculated by converting the request UNIX timestamp.\n",
    "\n",
    "```python\n",
    "batch_source = HdfsSource(name=\"nycTaxiBatchSource\",\n",
    "                          path=\"abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/demo_data/green_tripdata_2020-04.csv\",\n",
    "                          event_timestamp_column=\"lpep_dropoff_datetime\",\n",
    "                          timestamp_format=\"yyyy-MM-dd HH:mm:ss\")\n",
    "\n",
    "\n",
    "f_trip_distance = Feature(name=\"f_trip_distance\",\n",
    "                          feature_type=FLOAT, transform=\"trip_distance\")\n",
    "f_trip_time_duration = Feature(name=\"f_trip_time_duration\",\n",
    "                               feature_type=INT32,\n",
    "                               transform=\"time_duration(lpep_pickup_datetime, lpep_dropoff_datetime, 'minutes')\")\n",
    "\n",
    "features = [\n",
    "    f_trip_distance,\n",
    "    f_trip_time_duration,\n",
    "    Feature(name=\"f_is_long_trip_distance\",\n",
    "            feature_type=BOOLEAN,\n",
    "            transform=\"cast_float(trip_distance)>30\"),\n",
    "    Feature(name=\"f_day_of_week\",\n",
    "            feature_type=INT32,\n",
    "            transform=\"dayofweek(lpep_dropoff_datetime)\"),\n",
    "]\n",
    "\n",
    "request_anchor = FeatureAnchor(name=\"request_features\",\n",
    "                               source=INPUT_CONTEXT,\n",
    "                               features=features)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_source = HdfsSource(name=\"nycTaxiBatchSource\",\n",
    "                          path=\"abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/demo_data/green_tripdata_2020-04.csv\",\n",
    "                          event_timestamp_column=\"lpep_dropoff_datetime\",\n",
    "                          timestamp_format=\"yyyy-MM-dd HH:mm:ss\")\n",
    "\n",
    "\n",
    "f_trip_distance = Feature(name=\"f_trip_distance\",\n",
    "                          feature_type=FLOAT, transform=\"trip_distance\")\n",
    "f_trip_time_duration = Feature(name=\"f_trip_time_duration\",\n",
    "                               feature_type=INT32,\n",
    "                               transform=\"time_duration(lpep_pickup_datetime, lpep_dropoff_datetime, 'minutes')\")\n",
    "\n",
    "features = [\n",
    "    f_trip_distance,\n",
    "    f_trip_time_duration,\n",
    "    Feature(name=\"f_is_long_trip_distance\",\n",
    "            feature_type=BOOLEAN,\n",
    "            transform=\"cast_float(trip_distance)>30\"),\n",
    "    Feature(name=\"f_day_of_week\",\n",
    "            feature_type=INT32,\n",
    "            transform=\"dayofweek(lpep_dropoff_datetime)\"),\n",
    "]\n",
    "\n",
    "request_anchor = FeatureAnchor(name=\"request_features\",\n",
    "                               source=INPUT_CONTEXT,\n",
    "                               features=features)\n",
    "\n",
    "\n",
    "f_trip_time_distance = DerivedFeature(name=\"f_trip_time_distance\",\n",
    "                                      feature_type=FLOAT,\n",
    "                                      input_features=[\n",
    "                                          f_trip_distance, f_trip_time_duration],\n",
    "                                      transform=\"f_trip_distance * f_trip_time_duration\")\n",
    "\n",
    "f_trip_time_rounded = DerivedFeature(name=\"f_trip_time_rounded\",\n",
    "                                     feature_type=INT32,\n",
    "                                     input_features=[f_trip_time_duration],\n",
    "                                     transform=\"f_trip_time_duration % 10\")\n",
    "\n",
    "\n",
    "location_id = TypedKey(key_column=\"DOLocationID\",\n",
    "                       key_column_type=ValueType.INT32,\n",
    "                       description=\"location id in NYC\",\n",
    "                       full_name=\"nyc_taxi.location_id\")\n",
    "agg_features = [Feature(name=\"f_location_avg_fare\",\n",
    "                        key=location_id,\n",
    "                        feature_type=FLOAT,\n",
    "                        transform=WindowAggTransformation(agg_expr=\"cast_float(fare_amount)\",\n",
    "                                                          agg_func=\"AVG\",\n",
    "                                                          window=\"90d\")),\n",
    "                Feature(name=\"f_location_max_fare\",\n",
    "                        key=location_id,\n",
    "                        feature_type=FLOAT,\n",
    "                        transform=WindowAggTransformation(agg_expr=\"cast_float(fare_amount)\",\n",
    "                                                          agg_func=\"MAX\",\n",
    "                                                          window=\"90d\"))\n",
    "                ]\n",
    "\n",
    "agg_anchor = FeatureAnchor(name=\"aggregationFeatures\",\n",
    "                           source=batch_source,\n",
    "                           features=agg_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we need to build those features so that it can be consumed later. Note that we have to build both the \"anchor\" and the \"derived\" features (which is not anchored to a source)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.build_features(anchor_list=[agg_anchor, request_anchor], derived_feature_list=[\n",
    "                      f_trip_time_distance, f_trip_time_rounded])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training data using point-in-time correct feature join\n",
    "\n",
    "A training dataset usually contains entity id columns, multiple feature columns, event timestamp column and label/target column. \n",
    "\n",
    "To create a training dataset using Feathr, one needs to provide a feature join configuration file to specify\n",
    "what features and how these features should be joined to the observation data. The feature join config file mainly contains: \n",
    "\n",
    "1. The path of a dataset as the 'spine' for the to-be-created training dataset. We call this input 'spine' dataset the 'observation'\n",
    "   dataset. Typically, each row of the observation data contains: \n",
    "   a) Column(s) representing entity id(s), which will be used as the join key to look up(join) feature value. \n",
    "   b) A column representing the event time of the row. By default, Feathr will make sure the feature values joined have\n",
    "   a timestamp earlier than it, ensuring no data leakage in the resulting training dataset. \n",
    "   c) Other columns will be simply pass through onto the output training dataset.\n",
    "2. The key fields from the observation data, which are used to joined with the feature data.\n",
    "3. List of feature names to be joined with the observation data. The features must be defined in the feature\n",
    "   definition configs.\n",
    "4. The time information of the observation data used to compare with the feature's timestamp during the join.\n",
    "\n",
    "Create training dataset via:\n",
    "\n",
    "```python\n",
    "client.get_offline_features(observation_settings=settings,\n",
    "                            feature_query=feature_query,\n",
    "                            output_path=\"abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/demo_data/output.avro\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 21:01:37.964 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:38 - Uploading /var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_join_conf/feature_join.conf to cloud..\n",
      "2022-03-21 21:01:37.965 | INFO     | feathr._synapse_submission:upload_file:317 - Uploading file feature_join.conf\n",
      "2022-03-21 21:01:38.418 | INFO     | feathr._synapse_submission:upload_file:323 - /var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_join_conf/feature_join.conf is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/feature_join.conf\n",
      "2022-03-21 21:01:38.419 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:41 - /var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_join_conf/feature_join.conf is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/feature_join.conf\n",
      "2022-03-21 21:01:38.419 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:38 - Uploading /var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_conf/ to cloud..\n",
      "2022-03-21 21:01:38.420 | INFO     | feathr._synapse_submission:upload_file_to_workdir:305 - Uploading folder /var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_conf/\n",
      "2022-03-21 21:01:38.423 | INFO     | feathr._synapse_submission:upload_file:317 - Uploading file auto_generated_request_features.conf\n",
      "2022-03-21 21:01:38.881 | INFO     | feathr._synapse_submission:upload_file:323 - /private/var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_conf/auto_generated_request_features.conf is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_request_features.conf\n",
      "2022-03-21 21:01:38.884 | INFO     | feathr._synapse_submission:upload_file:317 - Uploading file auto_generated_anchored_features.conf\n",
      "2022-03-21 21:01:39.297 | INFO     | feathr._synapse_submission:upload_file:323 - /private/var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_conf/auto_generated_anchored_features.conf is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_anchored_features.conf\n",
      "2022-03-21 21:01:39.299 | INFO     | feathr._synapse_submission:upload_file:317 - Uploading file auto_generated_derived_features.conf\n",
      "2022-03-21 21:01:39.739 | INFO     | feathr._synapse_submission:upload_file:323 - /private/var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_conf/auto_generated_derived_features.conf is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_derived_features.conf\n",
      "2022-03-21 21:01:39.740 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:41 - /var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_conf/ is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_request_features.conf,abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_anchored_features.conf,abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_derived_features.conf\n",
      "2022-03-21 21:01:39.741 | INFO     | feathr._envvariableutil:get_environment_variable:61 - S3_ACCESS_KEY is not set in the environment variables.\n",
      "2022-03-21 21:01:39.742 | INFO     | feathr._envvariableutil:get_environment_variable:61 - S3_SECRET_KEY is not set in the environment variables.\n",
      "2022-03-21 21:01:39.743 | INFO     | feathr._envvariableutil:get_environment_variable:61 - ADLS_ACCOUNT is not set in the environment variables.\n",
      "2022-03-21 21:01:39.743 | INFO     | feathr._envvariableutil:get_environment_variable:61 - ADLS_KEY is not set in the environment variables.\n",
      "2022-03-21 21:01:39.744 | INFO     | feathr._envvariableutil:get_environment_variable:61 - BLOB_ACCOUNT is not set in the environment variables.\n",
      "2022-03-21 21:01:39.745 | INFO     | feathr._envvariableutil:get_environment_variable:61 - BLOB_KEY is not set in the environment variables.\n",
      "2022-03-21 21:01:39.746 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_TABLE is not set in the environment variables.\n",
      "2022-03-21 21:01:39.746 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_USER is not set in the environment variables.\n",
      "2022-03-21 21:01:39.747 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_PASSWORD is not set in the environment variables.\n",
      "2022-03-21 21:01:39.747 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_DRIVER is not set in the environment variables.\n",
      "2022-03-21 21:01:39.748 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_AUTH_FLAG is not set in the environment variables.\n",
      "2022-03-21 21:01:39.748 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_TOKEN is not set in the environment variables.\n",
      "2022-03-21 21:01:39.776 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_SF_PASSWORD is not set in the environment variables.\n",
      "2022-03-21 21:01:39.777 | INFO     | feathr._synapse_submission:submit_feathr_job:81 - Uploading jar from wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar to cloud for running job: feathr_sample_feathr_feature_join_job\n",
      "2022-03-21 21:01:39.777 | INFO     | feathr._synapse_submission:upload_file_to_workdir:300 - Skipping file wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar as it's already in the cloud\n",
      "2022-03-21 21:01:39.778 | INFO     | feathr._synapse_submission:submit_feathr_job:84 - wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar is uploaded to wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar for running job: feathr_sample_feathr_feature_join_job\n",
      "2022-03-21 21:01:41.093 | INFO     | feathr._synapse_submission:submit_feathr_job:99 - See submitted job here: https://web.azuresynapse.net/en-us/monitoring/sparkapplication\n",
      "2022-03-21 21:01:41.220 | INFO     | feathr._synapse_submission:wait_for_completion:109 - Current Spark job status: not_started\n",
      "2022-03-21 21:02:11.367 | INFO     | feathr._synapse_submission:wait_for_completion:109 - Current Spark job status: running\n",
      "2022-03-21 21:02:41.527 | INFO     | feathr._synapse_submission:wait_for_completion:109 - Current Spark job status: running\n",
      "2022-03-21 21:03:11.652 | INFO     | feathr._synapse_submission:wait_for_completion:109 - Current Spark job status: running\n",
      "2022-03-21 21:03:41.840 | INFO     | feathr._synapse_submission:wait_for_completion:109 - Current Spark job status: success\n"
     ]
    }
   ],
   "source": [
    "feature_query = FeatureQuery(\n",
    "    feature_list=[\"f_location_avg_fare\", \"f_trip_time_rounded\", \"f_is_long_trip_distance\"], key=location_id)\n",
    "settings = ObservationSettings(\n",
    "    observation_path=\"abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/demo_data/green_tripdata_2020-04.csv\",\n",
    "    event_timestamp_column=\"lpep_dropoff_datetime\",\n",
    "    timestamp_format=\"yyyy-MM-dd HH:mm:ss\")\n",
    "client.get_offline_features(observation_settings=settings,\n",
    "                            feature_query=feature_query,\n",
    "                            output_path=\"abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/demo_data/output.avro\")\n",
    "client.wait_job_to_finish(timeout_sec=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the result and show the result\n",
    "\n",
    "Let's use the helper function `get_result_df` to download the result and view it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 21:03:42.075 | INFO     | feathr._synapse_submission:wait_for_completion:109 - Current Spark job status: success\n",
      "2022-03-21 21:03:42.174 | INFO     | feathr._synapse_submission:download_file:334 - Beginning reading of results from abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/demo_data/output.avro\n",
      "2022-03-21 21:03:58.599 | INFO     | feathr._synapse_submission:download_file:355 - Finish downloading files from abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/demo_data/output.avro to /var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmpn9_zja46.\n"
     ]
    }
   ],
   "source": [
    "def get_result_df(client: FeathrClient) -> pd.DataFrame:\n",
    "    \"\"\"Download the job result dataset from cloud as a Pandas dataframe.\"\"\"\n",
    "    res_url = client.get_job_result_uri(block=True, timeout_sec=600)\n",
    "    tmp_dir = tempfile.TemporaryDirectory()\n",
    "    client.feathr_spark_laucher.download_result(result_path=res_url, local_folder=tmp_dir.name)\n",
    "    dataframe_list = []\n",
    "    # assuming the result are in avro format\n",
    "    for file in glob.glob(os.path.join(tmp_dir.name, '*.avro')):\n",
    "        dataframe_list.append(pdx.read_avro(file))\n",
    "    vertical_concat_df = pd.concat(dataframe_list, axis=0)\n",
    "    tmp_dir.cleanup()\n",
    "    return vertical_concat_df\n",
    "\n",
    "df_res = get_result_df(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>...</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>f_is_long_trip_distance</th>\n",
       "      <th>f_location_avg_fare</th>\n",
       "      <th>f_trip_time_rounded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-01 09:04:53</td>\n",
       "      <td>2020-04-01 09:16:06</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>3.36</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-01 10:59:12</td>\n",
       "      <td>2020-04-01 11:14:49</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-01 15:01:09</td>\n",
       "      <td>2020-04-01 15:14:03</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>2.48</td>\n",
       "      <td>11.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-01 15:34:25</td>\n",
       "      <td>2020-04-01 15:48:27</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>3.80</td>\n",
       "      <td>14.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-01 19:37:30</td>\n",
       "      <td>2020-04-01 19:50:10</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>2.95</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>None</td>\n",
       "      <td>2020-04-30 08:38:00</td>\n",
       "      <td>2020-04-30 08:47:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>None</td>\n",
       "      <td>1.61</td>\n",
       "      <td>7.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.79</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>None</td>\n",
       "      <td>2020-04-30 10:36:00</td>\n",
       "      <td>2020-04-30 10:52:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>238</td>\n",
       "      <td>247</td>\n",
       "      <td>None</td>\n",
       "      <td>7.34</td>\n",
       "      <td>16.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>None</td>\n",
       "      <td>2020-04-30 11:27:00</td>\n",
       "      <td>2020-04-30 11:35:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>247</td>\n",
       "      <td>None</td>\n",
       "      <td>1.44</td>\n",
       "      <td>7.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.88</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>None</td>\n",
       "      <td>2020-04-30 12:10:00</td>\n",
       "      <td>2020-04-30 12:16:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>235</td>\n",
       "      <td>247</td>\n",
       "      <td>None</td>\n",
       "      <td>.97</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.05</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>None</td>\n",
       "      <td>2020-04-30 23:03:00</td>\n",
       "      <td>2020-04-30 23:13:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>136</td>\n",
       "      <td>247</td>\n",
       "      <td>None</td>\n",
       "      <td>2.28</td>\n",
       "      <td>7.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.75</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35612 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0          2  2020-04-01 09:04:53   2020-04-01 09:16:06                  N   \n",
       "1          2  2020-04-01 10:59:12   2020-04-01 11:14:49                  N   \n",
       "2          2  2020-04-01 15:01:09   2020-04-01 15:14:03                  N   \n",
       "3          2  2020-04-01 15:34:25   2020-04-01 15:48:27                  N   \n",
       "4          2  2020-04-01 19:37:30   2020-04-01 19:50:10                  N   \n",
       "..       ...                  ...                   ...                ...   \n",
       "507     None  2020-04-30 08:38:00   2020-04-30 08:47:00               None   \n",
       "508     None  2020-04-30 10:36:00   2020-04-30 10:52:00               None   \n",
       "509     None  2020-04-30 11:27:00   2020-04-30 11:35:00               None   \n",
       "510     None  2020-04-30 12:10:00   2020-04-30 12:16:00               None   \n",
       "511     None  2020-04-30 23:03:00   2020-04-30 23:13:00               None   \n",
       "\n",
       "    RatecodeID PULocationID DOLocationID passenger_count trip_distance  \\\n",
       "0            5           42          147               1          3.36   \n",
       "1            1           75          147               1          2.50   \n",
       "2            1           42          147               1          2.48   \n",
       "3            1           42          147               1          3.80   \n",
       "4            1           42          147               1          2.95   \n",
       "..         ...          ...          ...             ...           ...   \n",
       "507       None          247          247            None          1.61   \n",
       "508       None          238          247            None          7.34   \n",
       "509       None           42          247            None          1.44   \n",
       "510       None          235          247            None           .97   \n",
       "511       None          136          247            None          2.28   \n",
       "\n",
       "    fare_amount  ... tolls_amount ehail_fee improvement_surcharge  \\\n",
       "0            15  ...            0      None                   0.3   \n",
       "1            13  ...            0      None                   0.3   \n",
       "2          11.5  ...            0      None                   0.3   \n",
       "3          14.5  ...            0      None                   0.3   \n",
       "4            12  ...            0      None                   0.3   \n",
       "..          ...  ...          ...       ...                   ...   \n",
       "507        7.86  ...            0      None                   0.3   \n",
       "508       16.25  ...            0      None                   0.3   \n",
       "509         7.1  ...            0      None                   0.3   \n",
       "510           8  ...            0      None                   0.3   \n",
       "511         7.2  ...            0      None                   0.3   \n",
       "\n",
       "    total_amount payment_type trip_type congestion_surcharge  \\\n",
       "0          16.18            1         2                    0   \n",
       "1           13.8            2         1                    0   \n",
       "2           12.3            2         1                    0   \n",
       "3           15.3            2         1                    0   \n",
       "4           13.8            2         1                    0   \n",
       "..           ...          ...       ...                  ...   \n",
       "507         9.79         None      None                 None   \n",
       "508         19.3         None      None                 None   \n",
       "509         8.88         None      None                 None   \n",
       "510        11.05         None      None                 None   \n",
       "511        10.75         None      None                 None   \n",
       "\n",
       "    f_is_long_trip_distance f_location_avg_fare f_trip_time_rounded  \n",
       "0                     False                15.0                   1  \n",
       "1                     False                15.0                   5  \n",
       "2                     False                15.0                   2  \n",
       "3                     False                15.0                   4  \n",
       "4                     False                15.0                   2  \n",
       "..                      ...                 ...                 ...  \n",
       "507                   False                 9.0                   9  \n",
       "508                   False                 9.0                   6  \n",
       "509                   False                 9.0                   8  \n",
       "510                   False                 9.0                   6  \n",
       "511                   False                 9.0                   0  \n",
       "\n",
       "[35612 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a machine learning model\n",
    "After getting all the features, let's train a machine learning model with the converted feature by Feathr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MAPE:\n",
      "0.02498496557554859\n",
      "\n",
      "Model Accuracy:\n",
      "0.9750150344244514\n"
     ]
    }
   ],
   "source": [
    "# remove columns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "final_df = df_res\n",
    "final_df.drop([\"lpep_pickup_datetime\", \"lpep_dropoff_datetime\",\n",
    "              \"store_and_fwd_flag\"], axis=1, inplace=True, errors='ignore')\n",
    "final_df.fillna(0, inplace=True)\n",
    "final_df['fare_amount'] = final_df['fare_amount'].astype(\"float64\")\n",
    "\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(final_df.drop([\"fare_amount\"], axis=1),\n",
    "                                                    final_df[\"fare_amount\"],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "y_predict = model.predict(test_x)\n",
    "\n",
    "y_actual = test_y.values.flatten().tolist()\n",
    "rmse = sqrt(mean_squared_error(y_actual, y_predict))\n",
    "\n",
    "sum_actuals = sum_errors = 0\n",
    "\n",
    "for actual_val, predict_val in zip(y_actual, y_predict):\n",
    "    abs_error = actual_val - predict_val\n",
    "    if abs_error < 0:\n",
    "        abs_error = abs_error * -1\n",
    "\n",
    "    sum_errors = sum_errors + abs_error\n",
    "    sum_actuals = sum_actuals + actual_val\n",
    "\n",
    "mean_abs_percent_error = sum_errors / sum_actuals\n",
    "print(\"Model MAPE:\")\n",
    "print(mean_abs_percent_error)\n",
    "print()\n",
    "print(\"Model Accuracy:\")\n",
    "print(1 - mean_abs_percent_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materialize feature value into offline/online storage\n",
    "\n",
    "While Feathr can compute the feature value from the feature definition on-the-fly at request time, it can also pre-compute\n",
    "and materialize the feature value to offline and/or online storage. \n",
    "\n",
    "We now want to push the generated features to the online store, so we configure the destination in the feature_gen config:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 21:04:02.559 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:38 - Uploading /var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_gen_conf/auto_gen_config_1589958000.0.conf to cloud..\n",
      "2022-03-21 21:04:02.560 | INFO     | feathr._synapse_submission:upload_file:317 - Uploading file auto_gen_config_1589958000.0.conf\n",
      "2022-03-21 21:04:03.092 | INFO     | feathr._synapse_submission:upload_file:323 - /var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_gen_conf/auto_gen_config_1589958000.0.conf is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_gen_config_1589958000.0.conf\n",
      "2022-03-21 21:04:03.094 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:41 - /var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_gen_conf/auto_gen_config_1589958000.0.conf is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_gen_config_1589958000.0.conf\n",
      "2022-03-21 21:04:03.095 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:38 - Uploading /var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_conf/ to cloud..\n",
      "2022-03-21 21:04:03.096 | INFO     | feathr._synapse_submission:upload_file_to_workdir:305 - Uploading folder /var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_conf/\n",
      "2022-03-21 21:04:03.098 | INFO     | feathr._synapse_submission:upload_file:317 - Uploading file auto_generated_request_features.conf\n",
      "2022-03-21 21:04:03.580 | INFO     | feathr._synapse_submission:upload_file:323 - /private/var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_conf/auto_generated_request_features.conf is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_request_features.conf\n",
      "2022-03-21 21:04:03.582 | INFO     | feathr._synapse_submission:upload_file:317 - Uploading file auto_generated_anchored_features.conf\n",
      "2022-03-21 21:04:04.002 | INFO     | feathr._synapse_submission:upload_file:323 - /private/var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_conf/auto_generated_anchored_features.conf is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_anchored_features.conf\n",
      "2022-03-21 21:04:04.004 | INFO     | feathr._synapse_submission:upload_file:317 - Uploading file auto_generated_derived_features.conf\n",
      "2022-03-21 21:04:04.453 | INFO     | feathr._synapse_submission:upload_file:323 - /private/var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_conf/auto_generated_derived_features.conf is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_derived_features.conf\n",
      "2022-03-21 21:04:04.455 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:41 - /var/folders/c0/h7cgkq4x56s__301z9203fw0001p3_/T/tmp6v6yjpzw/feature_conf/ is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_request_features.conf,abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_anchored_features.conf,abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_derived_features.conf\n",
      "2022-03-21 21:04:04.455 | INFO     | feathr._envvariableutil:get_environment_variable:61 - S3_ACCESS_KEY is not set in the environment variables.\n",
      "2022-03-21 21:04:04.456 | INFO     | feathr._envvariableutil:get_environment_variable:61 - S3_SECRET_KEY is not set in the environment variables.\n",
      "2022-03-21 21:04:04.457 | INFO     | feathr._envvariableutil:get_environment_variable:61 - ADLS_ACCOUNT is not set in the environment variables.\n",
      "2022-03-21 21:04:04.458 | INFO     | feathr._envvariableutil:get_environment_variable:61 - ADLS_KEY is not set in the environment variables.\n",
      "2022-03-21 21:04:04.458 | INFO     | feathr._envvariableutil:get_environment_variable:61 - BLOB_ACCOUNT is not set in the environment variables.\n",
      "2022-03-21 21:04:04.459 | INFO     | feathr._envvariableutil:get_environment_variable:61 - BLOB_KEY is not set in the environment variables.\n",
      "2022-03-21 21:04:04.460 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_TABLE is not set in the environment variables.\n",
      "2022-03-21 21:04:04.460 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_USER is not set in the environment variables.\n",
      "2022-03-21 21:04:04.461 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_PASSWORD is not set in the environment variables.\n",
      "2022-03-21 21:04:04.462 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_DRIVER is not set in the environment variables.\n",
      "2022-03-21 21:04:04.462 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_AUTH_FLAG is not set in the environment variables.\n",
      "2022-03-21 21:04:04.463 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_TOKEN is not set in the environment variables.\n",
      "2022-03-21 21:04:04.486 | INFO     | feathr._envvariableutil:get_environment_variable:61 - JDBC_SF_PASSWORD is not set in the environment variables.\n",
      "2022-03-21 21:04:04.487 | INFO     | feathr._synapse_submission:submit_feathr_job:81 - Uploading jar from wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar to cloud for running job: feathr_sample_feathr_feature_materialization_job\n",
      "2022-03-21 21:04:04.487 | INFO     | feathr._synapse_submission:upload_file_to_workdir:300 - Skipping file wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar as it's already in the cloud\n",
      "2022-03-21 21:04:04.488 | INFO     | feathr._synapse_submission:submit_feathr_job:84 - wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar is uploaded to wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar for running job: feathr_sample_feathr_feature_materialization_job\n",
      "2022-03-21 21:04:04.690 | INFO     | feathr._synapse_submission:submit_feathr_job:99 - See submitted job here: https://web.azuresynapse.net/en-us/monitoring/sparkapplication\n",
      "2022-03-21 21:04:04.802 | INFO     | feathr._synapse_submission:wait_for_completion:109 - Current Spark job status: not_started\n",
      "2022-03-21 21:04:34.962 | INFO     | feathr._synapse_submission:wait_for_completion:109 - Current Spark job status: starting\n",
      "2022-03-21 21:05:05.154 | INFO     | feathr._synapse_submission:wait_for_completion:109 - Current Spark job status: running\n",
      "2022-03-21 21:05:35.315 | INFO     | feathr._synapse_submission:wait_for_completion:109 - Current Spark job status: running\n",
      "2022-03-21 21:06:05.518 | INFO     | feathr._synapse_submission:wait_for_completion:109 - Current Spark job status: success\n"
     ]
    }
   ],
   "source": [
    "backfill_time = BackfillTime(start=datetime(\n",
    "    2020, 5, 20), end=datetime(2020, 5, 20), step=timedelta(days=1))\n",
    "redisSink = RedisSink(table_name=\"nycTaxiDemoFeature\")\n",
    "settings = MaterializationSettings(\"nycTaxiTable\",\n",
    "                                   backfill_time=backfill_time,\n",
    "                                   sinks=[redisSink],\n",
    "                                   feature_names=[\"f_location_avg_fare\", \"f_location_max_fare\"])\n",
    "\n",
    "client.materialize_features(settings)\n",
    "client.wait_job_to_finish(timeout_sec=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then get the features from the online store (Redis):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching feature value for online inference\n",
    "\n",
    "For features that are already materialized by the previous step, their latest value can be queried via the client's\n",
    "`get_online_features` or `multi_get_online_features` API.\n",
    "\n",
    "```python\n",
    "client.get_online_features(\"nycTaxiDemoFeature\", \"265\", ['f_location_avg_fare', 'f_location_max_fare'])\n",
    "client.multi_get_online_features(\"nycTaxiDemoFeature\", [\"239\", \"265\"], ['f_location_avg_fare', 'f_location_max_fare'])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.get_online_features('nycTaxiDemoFeature', '265', [\n",
    "                                 'f_location_avg_fare', 'f_location_max_fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'239': [10.5, 10.5], '265': [42.5, 42.5]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.multi_get_online_features(\"nycTaxiDemoFeature\", [\"239\", \"265\"], [\n",
    "                                 'f_location_avg_fare', 'f_location_max_fare'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f_location_max_fare',\n",
       " 'f_location_avg_fare',\n",
       " 'f_trip_distance',\n",
       " 'f_trip_time_duration',\n",
       " 'f_hour_of_day',\n",
       " 'f_is_long_trip_distance',\n",
       " 'f_day_of_month',\n",
       " 'f_day_of_week']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_registered_features(project_name=\"frame_getting_started\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "830c16c5b424e7ff512f67d4056b67cea1a756a7ad6a92c98b9e2b95c5e484ae"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
